# -*- coding: utf-8 -*-
"""XGB_prototypev2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dg_l4hUJdzGdftS4QhLVvaUW9_dopzvL
"""

"""
XGBoost Multi-Target Predictor for Seoul Bike System
Configurable for different targets and prediction horizons
Optimized for Google Colab
"""

# --- Colab & Drive setup ---
from google.colab import drive
drive.mount('/content/drive')

import os
import sys
import warnings
warnings.filterwarnings('ignore')

# Directory setup
BASE_DIR = '/content/drive/MyDrive/seoul_bikes'
MODELS_DIR = f'{BASE_DIR}/models'
DATA_DIR = f'{BASE_DIR}/data'

# Create directories if they don't exist
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

print(f"üìÅ Base directory: {BASE_DIR}")
print(f"üìÅ Models directory: {MODELS_DIR}")

# Check for existing parquet files
import glob
parquet_files = glob.glob(f"{BASE_DIR}/*.parquet")
print(f"üìä Found {len(parquet_files)} parquet files")
for f in parquet_files[:5]:
    print(f"  - {os.path.basename(f)}")

# Install XGBoost if needed
try:
    import xgboost as xgb
    print(f"‚úÖ XGBoost version: {xgb.__version__}")
except ImportError:
    print("Installing XGBoost...")
    !pip install xgboost
    import xgboost as xgb

import pandas as pd
import numpy as np
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import joblib
import json

# Set matplotlib backend for Colab
import matplotlib
matplotlib.use('Agg')

# Configure pandas display
pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 100)

class XGBoostFlexiblePredictor:
    """
    Flexible XGBoost predictor that can handle both classification and regression
    for different target variables and prediction horizons
    """

    def __init__(self, target_type='regression', target_column='target_net_flow_2h'):
        """
        Initialize predictor

        Args:
            target_type: 'regression' for continuous targets (net_flow, available_bikes)
                        'classification' for binary targets (stockout, nearly_empty)
            target_column: Name of target column to predict
        """
        self.target_type = target_type
        self.target_column = target_column
        self.model = None
        self.feature_cols = None

        # XGBoost parameters
        if target_type == 'regression':
            self.model_params = {
                'objective': 'reg:squarederror',
                'eval_metric': 'rmse',
                'eta': 0.05,
                'max_depth': 6,
                'subsample': 0.8,
                'colsample_bytree': 0.9,
                'seed': 42,
                'tree_method': 'hist',
                # 'device': 'cuda'  # Uncomment if GPU available in Colab
            }
        else:  # classification
            self.model_params = {
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'eta': 0.05,
                'max_depth': 6,
                'subsample': 0.8,
                'colsample_bytree': 0.9,
                'scale_pos_weight': 3,  # For imbalanced data
                'seed': 42,
                'tree_method': 'hist',
                # 'device': 'cuda'  # Uncomment if GPU available
            }

        self.metrics = {}
        self.optimal_threshold = None

    def load_data(self, train_file='lightgbm_train_2024.parquet', test_file='lightgbm_test_2024.parquet'):
        """Load prepared training and test data"""
        print(f"üìä Loading data for {self.target_column}...")

        # Find files
        train_path = None
        test_path = None

        # Check in BASE_DIR first
        if os.path.exists(f"{BASE_DIR}/{train_file}"):
            train_path = f"{BASE_DIR}/{train_file}"
            test_path = f"{BASE_DIR}/{test_file}"
        # Check in DATA_DIR
        elif os.path.exists(f"{DATA_DIR}/{train_file}"):
            train_path = f"{DATA_DIR}/{train_file}"
            test_path = f"{DATA_DIR}/{test_file}"
        else:
            raise FileNotFoundError(f"Cannot find {train_file}")

        print(f"üìÇ Loading from: {train_path}")

        train_df = pd.read_parquet(train_path)
        test_df = pd.read_parquet(test_path)

        # Check if target column exists
        if self.target_column not in train_df.columns:
            print(f"‚ùå Target column '{self.target_column}' not found!")
            print(f"Available targets: {[col for col in train_df.columns if 'target_' in col]}")
            raise ValueError(f"Target column '{self.target_column}' not found in data")

        print(f"Train shape: {train_df.shape}")
        print(f"Test shape: {test_df.shape}")

        # Define feature columns (exclude ALL targets and identifiers)
        exclude_cols = [
            'station_id', 'date', 'hour', 'day_of_week', 'season',
            'target_stockout_2h', 'target_nearly_empty_2h',
            'target_net_flow_2h', 'target_available_bikes_2h'
        ]

        self.feature_cols = [col for col in train_df.columns if col not in exclude_cols]
        print(f"Using {len(self.feature_cols)} features")

        # Prepare datasets
        X_train = train_df[self.feature_cols]
        y_train = train_df[self.target_column]
        X_test = test_df[self.feature_cols]
        y_test = test_df[self.target_column]

        # Convert to int for classification
        if self.target_type == 'classification':
            y_train = y_train.astype(int)
            y_test = y_test.astype(int)

        # Store metadata
        self.test_metadata = test_df[['station_id', 'date', 'hour']].copy()

        # Print target statistics
        print(f"\nüìà Target statistics for {self.target_column}:")
        if self.target_type == 'regression':
            print(f"Train: mean={y_train.mean():.2f}, std={y_train.std():.2f}")
            print(f"Test: mean={y_test.mean():.2f}, std={y_test.std():.2f}")
        else:
            print(f"Train: positive rate={y_train.mean():.3f} ({y_train.sum():,}/{len(y_train):,})")
            print(f"Test: positive rate={y_test.mean():.3f} ({y_test.sum():,}/{len(y_test):,})")

        return X_train, y_train, X_test, y_test

    def train_model(self, X_train, y_train, X_test, y_test):
        """Train XGBoost model with early stopping"""
        print(f"\nüèãÔ∏è Training XGBoost {self.target_type} model...")

        # Create DMatrix objects
        dtrain = xgb.DMatrix(X_train, label=y_train)
        dtest = xgb.DMatrix(X_test, label=y_test)

        # Setup evaluation list
        evallist = [(dtrain, 'train'), (dtest, 'eval')]

        # Train model
        self.model = xgb.train(
            self.model_params,
            dtrain,
            num_boost_round=1000,
            evals=evallist,
            early_stopping_rounds=50,
            verbose_eval=100
        )

        print(f"Best iteration: {self.model.best_iteration}")
        print(f"Best score: {self.model.best_score}")

        return self.model

    def evaluate_regression(self, X_test, y_test):
        """Evaluate regression model"""
        print("\nüìä Regression Model Evaluation")
        print("-"*40)

        dtest = xgb.DMatrix(X_test)
        y_pred = self.model.predict(dtest, iteration_range=(0, self.model.best_iteration))

        # Calculate metrics
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        # Calculate MAPE (avoiding division by zero)
        mask = y_test != 0
        mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100 if mask.any() else 0

        print(f"RMSE: {rmse:.3f}")
        print(f"MAE:  {mae:.3f}")
        print(f"MAPE: {mape:.1f}%")
        print(f"R¬≤:   {r2:.4f}")

        # Analyze errors by magnitude
        errors = y_pred - y_test
        print(f"\nüìà Error Distribution:")
        print(f"Mean error: {errors.mean():.3f}")
        print(f"Std error:  {errors.std():.3f}")
        print(f"95% of errors within: ¬±{1.96 * errors.std():.3f}")

        self.metrics = {
            'rmse': rmse,
            'mae': mae,
            'mape': mape,
            'r2': r2,
            'mean_error': errors.mean(),
            'std_error': errors.std()
        }

        return y_pred, self.metrics

    def evaluate_classification(self, X_test, y_test):
        """Evaluate classification model"""
        print("\nüìä Classification Model Evaluation")
        print("-"*40)

        dtest = xgb.DMatrix(X_test)
        y_pred_proba = self.model.predict(dtest, iteration_range=(0, self.model.best_iteration))

        # Find optimal threshold
        thresholds = np.arange(0.1, 0.91, 0.05)
        best_f1 = 0
        best_threshold = 0.5

        for threshold in thresholds:
            y_pred = (y_pred_proba > threshold).astype(int)
            f1 = f1_score(y_test, y_pred)
            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold

        self.optimal_threshold = best_threshold
        y_pred = (y_pred_proba > best_threshold).astype(int)

        # Calculate metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)

        print(f"Optimal Threshold: {best_threshold:.2f}")
        print(f"Accuracy:  {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall:    {recall:.4f}")
        print(f"F1-Score:  {f1:.4f}")

        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        print(f"\nüî¢ Confusion Matrix:")
        print(f"True Neg: {cm[0,0]:,} | False Pos: {cm[0,1]:,}")
        print(f"False Neg: {cm[1,0]:,} | True Pos: {cm[1,1]:,}")

        self.metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'optimal_threshold': best_threshold,
            'confusion_matrix': cm.tolist()
        }

        return y_pred, self.metrics

    def plot_predictions(self, X_test, y_test, sample_stations=3, hours_to_plot=168):
        """Plot actual vs predicted values for sample stations"""
        print("\nüìä Generating prediction plots...")

        dtest = xgb.DMatrix(X_test)
        y_pred = self.model.predict(dtest, iteration_range=(0, self.model.best_iteration))

        # For classification, convert probabilities to binary
        if self.target_type == 'classification' and self.optimal_threshold:
            y_pred = (y_pred > self.optimal_threshold).astype(int)

        # Create results dataframe
        results_df = self.test_metadata.copy()
        results_df['actual'] = y_test.values
        results_df['predicted'] = y_pred
        results_df['datetime'] = pd.to_datetime(results_df['date'].astype(str) + ' ' + results_df['hour'].astype(str) + ':00:00')

        # Sample stations to plot
        stations = results_df['station_id'].unique()[:sample_stations]

        fig, axes = plt.subplots(sample_stations, 1, figsize=(15, 4*sample_stations))
        if sample_stations == 1:
            axes = [axes]

        for idx, station in enumerate(stations):
            station_data = results_df[results_df['station_id'] == station].sort_values('datetime').head(hours_to_plot)

            ax = axes[idx]
            ax.plot(station_data['datetime'], station_data['actual'], label='Actual', alpha=0.7, linewidth=2)
            ax.plot(station_data['datetime'], station_data['predicted'], label='Predicted', alpha=0.7, linewidth=2)
            ax.set_title(f'Station {station} - {self.target_column}')
            ax.set_xlabel('Time')
            ax.set_ylabel('Value' if self.target_type == 'regression' else 'Binary State')
            ax.legend()
            ax.grid(True, alpha=0.3)

            # Rotate x-axis labels
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')

        plt.tight_layout()

        # Save figure
        plot_path = f'{MODELS_DIR}/xgb_{self.target_column}_predictions.png'
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.show()
        print(f"üíæ Saved plot: {plot_path}")

        return results_df

    def plot_feature_importance(self, top_n=20):
        """Plot feature importance"""
        # Get feature importance
        importance_dict = self.model.get_score(importance_type='gain')

        # Convert to DataFrame
        importance_df = pd.DataFrame({
            'feature': list(importance_dict.keys()),
            'importance': list(importance_dict.values())
        })

        # Map feature names if needed
        if importance_df['feature'].iloc[0].startswith('f'):
            feature_mapping = {f'f{i}': self.feature_cols[i] for i in range(len(self.feature_cols))}
            importance_df['feature'] = importance_df['feature'].map(feature_mapping)

        importance_df = importance_df.sort_values('importance', ascending=False).head(top_n)

        # Plot
        plt.figure(figsize=(10, 8))
        sns.barplot(data=importance_df, x='importance', y='feature')
        plt.title(f'Top {top_n} Feature Importance - {self.target_column}')
        plt.xlabel('Importance (Gain)')
        plt.tight_layout()

        # Save
        plot_path = f'{MODELS_DIR}/xgb_{self.target_column}_importance.png'
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.show()
        print(f"üíæ Saved importance plot: {plot_path}")

        return importance_df

    def analyze_temporal_patterns(self, X_test, y_test):
        """Analyze prediction performance by time periods"""
        print("\n‚è∞ Temporal Pattern Analysis")
        print("-"*40)

        dtest = xgb.DMatrix(X_test)
        y_pred = self.model.predict(dtest, iteration_range=(0, self.model.best_iteration))

        # Create analysis dataframe
        analysis_df = self.test_metadata.copy()
        analysis_df['actual'] = y_test.values
        analysis_df['predicted'] = y_pred
        analysis_df['error'] = y_pred - y_test.values if self.target_type == 'regression' else None

        # Add temporal features
        analysis_df['day_of_week'] = pd.to_datetime(analysis_df['date']).dt.dayofweek
        analysis_df['is_weekend'] = analysis_df['day_of_week'].isin([5, 6]).astype(int)

        # Hourly analysis
        if self.target_type == 'regression':
            hourly_mae = analysis_df.groupby('hour')['error'].apply(lambda x: np.abs(x).mean())
            print("\nüìä Mean Absolute Error by Hour:")
            print(f"Best hours: {hourly_mae.nsmallest(3).index.tolist()} (MAE: {hourly_mae.min():.2f})")
            print(f"Worst hours: {hourly_mae.nlargest(3).index.tolist()} (MAE: {hourly_mae.max():.2f})")

            # Weekend vs Weekday
            weekend_mae = analysis_df.groupby('is_weekend')['error'].apply(lambda x: np.abs(x).mean())
            print(f"\nüìÖ Weekend vs Weekday MAE:")
            print(f"Weekday: {weekend_mae[0]:.2f}")
            print(f"Weekend: {weekend_mae[1]:.2f}")
        else:
            # For classification
            analysis_df['predicted_binary'] = (y_pred > self.optimal_threshold).astype(int)
            hourly_acc = analysis_df.groupby('hour').apply(
                lambda x: accuracy_score(x['actual'], x['predicted_binary'])
            )
            print("\nüìä Accuracy by Hour:")
            print(f"Best hours: {hourly_acc.nlargest(3).index.tolist()} (Acc: {hourly_acc.max():.3f})")
            print(f"Worst hours: {hourly_acc.nsmallest(3).index.tolist()} (Acc: {hourly_acc.min():.3f})")

        return analysis_df

    def save_model_and_config(self):
        """Save trained model and configuration"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Save XGBoost model
        model_path = f'{MODELS_DIR}/xgb_{self.target_column}_{timestamp}.json'
        self.model.save_model(model_path)

        # Also save as pickle
        pkl_path = f'{MODELS_DIR}/xgb_{self.target_column}_{timestamp}.pkl'
        joblib.dump(self.model, pkl_path)

        # Save configuration
        config = {
            'model_info': {
                'model_type': f'XGBoost {self.target_type}',
                'target': self.target_column,
                'features': self.feature_cols,
                'num_features': len(self.feature_cols),
                'model_params': self.model_params,
                'best_iteration': self.model.best_iteration,
                'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            },
            'metrics': self.metrics
        }

        if self.optimal_threshold:
            config['optimal_threshold'] = float(self.optimal_threshold)

        config_path = f'{MODELS_DIR}/xgb_{self.target_column}_config_{timestamp}.json'
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)

        print(f"\nüíæ Model saved:")
        print(f"  - XGBoost model: {model_path}")
        print(f"  - Configuration: {config_path}")

        return model_path, config_path

    def run_full_pipeline(self):
        """Execute complete training and evaluation pipeline"""
        print("="*60)
        print(f"üöÄ XGBoost {self.target_type.upper()} PIPELINE")
        print(f"üéØ Target: {self.target_column}")
        print("="*60)

        # Load data
        X_train, y_train, X_test, y_test = self.load_data()

        # Train model
        self.train_model(X_train, y_train, X_test, y_test)

        # Evaluate based on type
        if self.target_type == 'regression':
            y_pred, metrics = self.evaluate_regression(X_test, y_test)
        else:
            y_pred, metrics = self.evaluate_classification(X_test, y_test)

        # Analyze temporal patterns
        analysis_df = self.analyze_temporal_patterns(X_test, y_test)

        # Plot predictions
        results_df = self.plot_predictions(X_test, y_test)

        # Feature importance
        importance_df = self.plot_feature_importance()

        # Save model
        model_path, config_path = self.save_model_and_config()

        # Final summary
        print("\n" + "="*60)
        print("‚úÖ TRAINING COMPLETE")
        print("="*60)

        if self.target_type == 'regression':
            print(f"üìä Final RMSE: {metrics['rmse']:.3f}")
            print(f"üìä Final R¬≤: {metrics['r2']:.4f}")
        else:
            print(f"üìä Final F1: {metrics['f1_score']:.3f}")
            print(f"üìä Optimal Threshold: {self.optimal_threshold:.2f}")

        return self.model, metrics, importance_df

# --- MAIN EXECUTION ---
if __name__ == "__main__":
    print("üñ•Ô∏è System Info:")
    print(f"  - Python: {sys.version}")
    print(f"  - XGBoost: {xgb.__version__}")

    # Check GPU availability
    try:
        import tensorflow as tf
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"  - GPU Available: {gpus}")
    except:
        pass

    print("\n" + "="*60)
    print("SELECT YOUR PREDICTION TARGET")
    print("="*60)
    print("\nAvailable targets:")
    print("1. target_net_flow_2h (regression) - Predict net bike flow")
    print("2. target_available_bikes_2h (regression) - Predict available bikes")
    print("3. target_stockout_2h (classification) - Predict stockout events")
    print("4. target_nearly_empty_2h (classification) - Predict nearly empty")

    # You can change these settings
    TARGET_COLUMN = 'target_net_flow_2h'  # Change this to your desired target
    TARGET_TYPE = 'regression'  # 'regression' or 'classification'

    print(f"\nüéØ Selected: {TARGET_COLUMN} ({TARGET_TYPE})")

    # Create and run predictor
    predictor = XGBoostFlexiblePredictor(
        target_type=TARGET_TYPE,
        target_column=TARGET_COLUMN
    )

    model, metrics, importance = predictor.run_full_pipeline()

    print("\n‚úÖ All done! Check your Google Drive for saved models and plots.")

    # --- OPTIONAL: Train multiple targets ---
    # Uncomment to train all targets sequentially
    """
    targets_config = [
        ('target_net_flow_2h', 'regression'),
        ('target_available_bikes_2h', 'regression'),
        ('target_stockout_2h', 'classification'),
        ('target_nearly_empty_2h', 'classification')
    ]

    all_results = {}
    for target_col, target_type in targets_config:
        print(f"\n{'='*60}")
        print(f"Training {target_col} ({target_type})")
        print('='*60)

        predictor = XGBoostFlexiblePredictor(
            target_type=target_type,
            target_column=target_col
        )

        model, metrics, importance = predictor.run_full_pipeline()
        all_results[target_col] = metrics

    # Print summary
    print("\n" + "="*60)
    print("ALL MODELS SUMMARY")
    print("="*60)
    for target, metrics in all_results.items():
        print(f"\n{target}:")
        for metric, value in metrics.items():
            if isinstance(value, (int, float)):
                print(f"  - {metric}: {value:.4f}")
    """